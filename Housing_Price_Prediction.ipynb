{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EpXOGB7L48XrKoYFah5Yc1Chyg2yhjEg",
      "authorship_tag": "ABX9TyPbm+zjdZ7tGqmCcHPbDhLx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AviWilbur/AviWilbur-ML_Housing_Prices/blob/main/Housing_Price_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "machine learning techniques to two different datasets: one for predicting customer churn and another related to housing prices in Paris. The project involves data preprocessing steps such as handling missing values, encoding categorical variables, and scaling features. It utilizes various machine learning models, including Random Forest, XGBoost, and neural networks, to build predictive models. Additionally, the project includes hyperparameter tuning using GridSearchCV and evaluates model performance using metrics like precision, recall, and F1-score. The goal is to optimize the models for accurate predictions in both classification and regression tasks. ​"
      ],
      "metadata": {
        "id": "lRBc90MxXxTa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A1tGVvvUlRE"
      },
      "outputs": [],
      "source": [
        "# א1\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import resample\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score,f1_score\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "classification = files.upload()\n",
        "\n",
        "from google.colab import files\n",
        "regression = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "HhugIxfMGkgC",
        "outputId": "3973f84f-cf8c-412f-88c4-4b11743327dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-920d2129-abc8-4dd7-b099-f133953083d2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-920d2129-abc8-4dd7-b099-f133953083d2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Bank Customer Churn Prediction.csv to Bank Customer Churn Prediction (2).csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6b8e03c4-05bf-42d1-9983-8a03455dbe28\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6b8e03c4-05bf-42d1-9983-8a03455dbe28\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ParisHousing1.csv to ParisHousing1 (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# א2\n",
        "# Load the first dataset into a DataFrame\n",
        "ds1 = pd.read_csv(\"Bank Customer Churn Prediction.csv\")\n",
        "\n",
        "ds2 = pd.read_csv(\"ParisHousing1.csv\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X1 = ds1.drop(\"churn\", axis=1)  # X contains all columns except \"churn\"\n",
        "y1 = ds1[\"churn\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X2 = ds2.drop(\"price\", axis=1)  # X contains all columns except \"churn\"\n",
        "y2 = ds2[\"price\"]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0EBbytQZU8cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3\n",
        "def preliminary_processing(X, y, z):\n",
        "    # Step 1: Check for missing values and fill them\n",
        "    numeric_features = X.select_dtypes(include=['number']).columns\n",
        "    categorical_features = X.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median'))\n",
        "    ])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numeric_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ])\n",
        "\n",
        "    # Step 2: Remove categorical columns with more than 4 categories\n",
        "    for col in categorical_features:\n",
        "        if X[col].nunique() > 4:\n",
        "            X.drop(col, axis=1, inplace=True)\n",
        "\n",
        "    # Step 3: Convert categorical variables with 4 categories or fewer into dummy variables\n",
        "    X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "    # Step 4: Normalize the entire data (both numerical and one-hot encoded categorical features)\n",
        "    scaler = StandardScaler()\n",
        "    X_processed = scaler.fit_transform(X_processed)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if z == 1:\n",
        "                # Display/print class frequencies\n",
        "        class_counts = y.value_counts()\n",
        "        print(\"Class Frequencies:\")\n",
        "        print(class_counts)\n",
        "\n",
        "        # Create and display a bar graph of class frequencies\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        class_counts.plot(kind='bar', color='skyblue')\n",
        "        plt.title('Class Frequencies')\n",
        "        plt.xlabel('Classes')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.xticks(rotation=0)\n",
        "        plt.show()\n",
        "        # Step 4: Balance classes if needed (less than 25% in one category)\n",
        "        minority_class = class_counts.idxmin()\n",
        "        majority_class = class_counts.idxmax()\n",
        "\n",
        "        if class_counts.min() / class_counts.max() < 0.25:\n",
        "            minority_samples = X_processed[y == minority_class]\n",
        "            majority_samples = X_processed[y == majority_class]\n",
        "\n",
        "            # Resample minority class to match the majority class\n",
        "            minority_samples_resampled = resample(minority_samples,\n",
        "                                                  n_samples=class_counts[majority_class],\n",
        "                                                  random_state=42)\n",
        "\n",
        "            # Combine minority and majority samples\n",
        "            X_processed_balanced = pd.concat([majority_samples, minority_samples_resampled])\n",
        "            y_balanced = pd.concat([y[y == majority_class], y[y == minority_class]])\n",
        "\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X_processed_balanced, y_balanced,\n",
        "                                                                test_size=0.2)\n",
        "\n",
        "            return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_processed, y,\n",
        "                                                        test_size=0.2)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "_Q4Irt_aAhPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1_train, X1_test, y1_train, y1_test = preliminary_processing(X1, y1,1)\n"
      ],
      "metadata": {
        "id": "R3zNV-pq6vgB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "c05f97e4-089c-4adb-fe32-0c6c5288beac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Frequencies:\n",
            "0    7963\n",
            "1    2037\n",
            "Name: churn, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "imbalanced data: since one class is much more frequent than the other imbalancing is required, I have chosen the resampling technique since it artificailly adds to the minority class to create a balanced dataset to prevent a bias towards the majority class."
      ],
      "metadata": {
        "id": "8HVp7axuZHBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "\n",
        "# Define hyperparameter grids for Random Forest and XGBoost\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],  # Example values, adjust as needed\n",
        "    'max_depth': [None, 10, 20],      # Example values, adjust as needed\n",
        "}\n",
        "\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [100, 200, 300],  # Example values, adjust as needed\n",
        "    'max_depth': [3, 4, 5],           # Example values, adjust as needed\n",
        "}\n",
        "\n",
        "# Create GridSearchCV objects for Random Forest and XGBoost\n",
        "rf_grid_search = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5)\n",
        "xgb_grid_search = GridSearchCV(xgb.XGBClassifier(random_state=42), xgb_param_grid, cv=5)\n",
        "\n",
        "# Fit the GridSearchCV objects on the training set\n",
        "rf_grid_search.fit(X1_train, y1_train)\n",
        "xgb_grid_search.fit(X1_train, y1_train)\n",
        "\n",
        "# Retrieve the best hyperparameters for each model\n",
        "best_rf_params = rf_grid_search.best_params_\n",
        "best_xgb_params = xgb_grid_search.best_params_\n",
        "\n",
        "# Now, you have the best hyperparameters for Random Forest and XGBoost models\n",
        "\n",
        "print(\"Best Hyperparameters for Random Forest:\")\n",
        "print(rf_grid_search.best_params_)\n",
        "\n",
        "print(\"\\nBest Hyperparameters for XGBoost:\")\n",
        "print(xgb_grid_search.best_params_)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3UOaJeanXBgC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c305bb60-3bfa-4873-b16b-2d487268a7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters for Random Forest:\n",
            "{'max_depth': 10, 'n_estimators': 100}\n",
            "\n",
            "Best Hyperparameters for XGBoost:\n",
            "{'max_depth': 3, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5\n",
        "\n",
        "\n",
        "\n",
        "# # Split the remaining data into validation (50%) and test (50%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X1_train, y1_train, test_size=0.5, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=128, activation='relu', input_dim=8))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=16, activation='relu'))\n",
        "# model.add(Dropout(0.5))  # Dropout layer for regularization\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(lr=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Define batch size and number of epochs\n",
        "batch_size = 64\n",
        "epochs = 100  # Experiment with the number of epochs\n",
        "\n",
        "# Define EarlyStopping callback to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model with validation\n",
        "history = model.fit(\n",
        "    X1_train,\n",
        "    y1_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[early_stopping],\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X1_test, y1_test)\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# Print the test accuracy\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "53yx2mPth7J7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c673c7e5-0973-4750-ea1f-627eea2c125f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 2s 5ms/step - loss: 0.4588 - accuracy: 0.8010 - val_loss: 0.3849 - val_accuracy: 0.8482\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8506 - val_loss: 0.3494 - val_accuracy: 0.8602\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.8569 - val_loss: 0.3398 - val_accuracy: 0.8633\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8561 - val_loss: 0.3344 - val_accuracy: 0.8635\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8595 - val_loss: 0.3322 - val_accuracy: 0.8655\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8587 - val_loss: 0.3281 - val_accuracy: 0.8662\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8620 - val_loss: 0.3264 - val_accuracy: 0.8675\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8612 - val_loss: 0.3270 - val_accuracy: 0.8698\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8624 - val_loss: 0.3264 - val_accuracy: 0.8673\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8630 - val_loss: 0.3208 - val_accuracy: 0.8690\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8624 - val_loss: 0.3235 - val_accuracy: 0.8673\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8643 - val_loss: 0.3181 - val_accuracy: 0.8740\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.8655 - val_loss: 0.3148 - val_accuracy: 0.8723\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8643 - val_loss: 0.3098 - val_accuracy: 0.8780\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8645 - val_loss: 0.3138 - val_accuracy: 0.8760\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.8661 - val_loss: 0.3087 - val_accuracy: 0.8763\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.8690 - val_loss: 0.3066 - val_accuracy: 0.8788\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3190 - accuracy: 0.8709 - val_loss: 0.3071 - val_accuracy: 0.8813\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8736 - val_loss: 0.3065 - val_accuracy: 0.8755\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3143 - accuracy: 0.8716 - val_loss: 0.3015 - val_accuracy: 0.8758\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3134 - accuracy: 0.8716 - val_loss: 0.2975 - val_accuracy: 0.8788\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3126 - accuracy: 0.8700 - val_loss: 0.2952 - val_accuracy: 0.8840\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3088 - accuracy: 0.8724 - val_loss: 0.2965 - val_accuracy: 0.8827\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3095 - accuracy: 0.8731 - val_loss: 0.2927 - val_accuracy: 0.8815\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3058 - accuracy: 0.8751 - val_loss: 0.2890 - val_accuracy: 0.8845\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.3029 - accuracy: 0.8770 - val_loss: 0.2874 - val_accuracy: 0.8838\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3026 - accuracy: 0.8759 - val_loss: 0.2873 - val_accuracy: 0.8842\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8779 - val_loss: 0.2823 - val_accuracy: 0.8878\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2976 - accuracy: 0.8774 - val_loss: 0.2813 - val_accuracy: 0.8885\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8773 - val_loss: 0.2798 - val_accuracy: 0.8903\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2953 - accuracy: 0.8799 - val_loss: 0.2773 - val_accuracy: 0.8898\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2937 - accuracy: 0.8814 - val_loss: 0.2733 - val_accuracy: 0.8888\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2899 - accuracy: 0.8811 - val_loss: 0.2724 - val_accuracy: 0.8913\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2878 - accuracy: 0.8819 - val_loss: 0.2782 - val_accuracy: 0.8863\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.8839 - val_loss: 0.2772 - val_accuracy: 0.8850\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.8813 - val_loss: 0.2644 - val_accuracy: 0.8923\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.8829 - val_loss: 0.2647 - val_accuracy: 0.8930\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.8864 - val_loss: 0.2712 - val_accuracy: 0.8878\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.8852 - val_loss: 0.2594 - val_accuracy: 0.8928\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2738 - accuracy: 0.8888 - val_loss: 0.2566 - val_accuracy: 0.8925\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.8878 - val_loss: 0.2601 - val_accuracy: 0.8932\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.8878 - val_loss: 0.2474 - val_accuracy: 0.9022\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.8856 - val_loss: 0.2536 - val_accuracy: 0.8925\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.8882 - val_loss: 0.2473 - val_accuracy: 0.8975\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2631 - accuracy: 0.8904 - val_loss: 0.2533 - val_accuracy: 0.8950\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2615 - accuracy: 0.8917 - val_loss: 0.2448 - val_accuracy: 0.9010\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.8926 - val_loss: 0.2391 - val_accuracy: 0.9035\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.8942 - val_loss: 0.2394 - val_accuracy: 0.9022\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.8941 - val_loss: 0.2368 - val_accuracy: 0.9053\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2532 - accuracy: 0.8959 - val_loss: 0.2412 - val_accuracy: 0.9030\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2567 - accuracy: 0.8945 - val_loss: 0.2355 - val_accuracy: 0.9068\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2508 - accuracy: 0.8979 - val_loss: 0.2370 - val_accuracy: 0.9025\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2494 - accuracy: 0.8978 - val_loss: 0.2311 - val_accuracy: 0.9095\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2443 - accuracy: 0.9001 - val_loss: 0.2243 - val_accuracy: 0.9090\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2480 - accuracy: 0.8979 - val_loss: 0.2328 - val_accuracy: 0.9065\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2439 - accuracy: 0.8970 - val_loss: 0.2265 - val_accuracy: 0.9082\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.2386 - accuracy: 0.9021 - val_loss: 0.2259 - val_accuracy: 0.9143\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.2368 - accuracy: 0.9024 - val_loss: 0.2261 - val_accuracy: 0.9075\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2364 - accuracy: 0.9039 - val_loss: 0.2117 - val_accuracy: 0.9137\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2354 - accuracy: 0.9000 - val_loss: 0.2158 - val_accuracy: 0.9133\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2316 - accuracy: 0.9066 - val_loss: 0.2156 - val_accuracy: 0.9145\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2287 - accuracy: 0.9054 - val_loss: 0.2082 - val_accuracy: 0.9153\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2277 - accuracy: 0.9080 - val_loss: 0.2105 - val_accuracy: 0.9135\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.9053 - val_loss: 0.2154 - val_accuracy: 0.9115\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2221 - accuracy: 0.9079 - val_loss: 0.2087 - val_accuracy: 0.9172\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.9038 - val_loss: 0.2123 - val_accuracy: 0.9147\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2218 - accuracy: 0.9085 - val_loss: 0.1945 - val_accuracy: 0.9222\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2203 - accuracy: 0.9072 - val_loss: 0.2013 - val_accuracy: 0.9160\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2212 - accuracy: 0.9069 - val_loss: 0.1998 - val_accuracy: 0.9172\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9140 - val_loss: 0.1964 - val_accuracy: 0.9197\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2173 - accuracy: 0.9094 - val_loss: 0.1909 - val_accuracy: 0.9225\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2126 - accuracy: 0.9114 - val_loss: 0.1870 - val_accuracy: 0.9250\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2032 - accuracy: 0.9179 - val_loss: 0.1818 - val_accuracy: 0.9273\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.2032 - accuracy: 0.9180 - val_loss: 0.1857 - val_accuracy: 0.9225\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2025 - accuracy: 0.9168 - val_loss: 0.1950 - val_accuracy: 0.9168\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.2079 - accuracy: 0.9131 - val_loss: 0.1831 - val_accuracy: 0.9280\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1988 - accuracy: 0.9180 - val_loss: 0.1836 - val_accuracy: 0.9262\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1988 - accuracy: 0.9171 - val_loss: 0.1760 - val_accuracy: 0.9285\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9220 - val_loss: 0.1766 - val_accuracy: 0.9305\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1905 - accuracy: 0.9209 - val_loss: 0.1700 - val_accuracy: 0.9308\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1932 - accuracy: 0.9210 - val_loss: 0.1704 - val_accuracy: 0.9315\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1933 - accuracy: 0.9196 - val_loss: 0.1742 - val_accuracy: 0.9275\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1907 - accuracy: 0.9202 - val_loss: 0.1723 - val_accuracy: 0.9310\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1913 - accuracy: 0.9210 - val_loss: 0.1686 - val_accuracy: 0.9333\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1977 - accuracy: 0.9159 - val_loss: 0.1709 - val_accuracy: 0.9270\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1825 - accuracy: 0.9236 - val_loss: 0.1642 - val_accuracy: 0.9367\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1799 - accuracy: 0.9273 - val_loss: 0.1587 - val_accuracy: 0.9345\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1796 - accuracy: 0.9236 - val_loss: 0.1576 - val_accuracy: 0.9365\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.1810 - accuracy: 0.9256 - val_loss: 0.1583 - val_accuracy: 0.9362\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1702 - accuracy: 0.9315 - val_loss: 0.1514 - val_accuracy: 0.9362\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1737 - accuracy: 0.9286 - val_loss: 0.1494 - val_accuracy: 0.9427\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9290 - val_loss: 0.1696 - val_accuracy: 0.9308\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1720 - accuracy: 0.9276 - val_loss: 0.1494 - val_accuracy: 0.9373\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1700 - accuracy: 0.9280 - val_loss: 0.1535 - val_accuracy: 0.9435\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1740 - accuracy: 0.9268 - val_loss: 0.1516 - val_accuracy: 0.9398\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1665 - accuracy: 0.9327 - val_loss: 0.1516 - val_accuracy: 0.9380\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1680 - accuracy: 0.9298 - val_loss: 0.1691 - val_accuracy: 0.9320\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.1711 - accuracy: 0.9299 - val_loss: 0.1459 - val_accuracy: 0.9417\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1633 - accuracy: 0.9324 - val_loss: 0.1429 - val_accuracy: 0.9410\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9342 - val_loss: 0.1395 - val_accuracy: 0.9438\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.8095\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 128)               1152      \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12033 (47.00 KB)\n",
            "Trainable params: 12033 (47.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Test Accuracy: 0.809499979019165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The neural network has 5 layers including the output layer with the sigmoid activation. The network has 12033 parameters. I have given these input parameters after expirementing with them and found that these inputs gave the best accuracy for the data."
      ],
      "metadata": {
        "id": "esDe0Ep1SfME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6\n",
        "\n",
        "# Make predictions using the Random Forest model\n",
        "rf_train_predictions = rf_grid_search.predict(X1_train)\n",
        "rf_test_predictions = rf_grid_search.predict(X1_test)\n",
        "\n",
        "# Make predictions using the XGBoost model\n",
        "xgb_train_predictions = xgb_grid_search.predict(X1_train)\n",
        "xgb_test_predictions = xgb_grid_search.predict(X1_test)\n",
        "\n",
        "# Make predictions using the Neural Network model\n",
        "nn_train_probabilities = model.predict(X1_train)\n",
        "nn_test_probabilities = model.predict(X1_test)\n",
        "\n",
        "# Threshold the predicted probabilities to get predicted classes\n",
        "nn_train_predictions = (nn_train_probabilities > 0.5).astype(int)\n",
        "nn_test_predictions = (nn_test_probabilities > 0.5).astype(int)\n",
        "\n",
        "# Print classification reports for Random Forest predictions\n",
        "print(\"Classification Report for Random Forest - Training Set:\")\n",
        "print(classification_report(y1_train, rf_train_predictions))\n",
        "\n",
        "print(\"\\nClassification Report for Random Forest - Test Set:\")\n",
        "print(classification_report(y1_test, rf_test_predictions))\n",
        "\n",
        "# Print classification reports for XGBoost predictions\n",
        "print(\"\\nClassification Report for XGBoost - Training Set:\")\n",
        "print(classification_report(y1_train, xgb_train_predictions))\n",
        "\n",
        "print(\"\\nClassification Report for XGBoost - Test Set:\")\n",
        "print(classification_report(y1_test, xgb_test_predictions))\n",
        "\n",
        "# Print classification reports for Neural Network predictions\n",
        "print(\"\\nClassification Report for Neural Network - Training Set:\")\n",
        "print(classification_report(y1_train, nn_train_predictions))\n",
        "\n",
        "print(\"\\nClassification Report for Neural Network - Test Set:\")\n",
        "print(classification_report(y1_test, nn_test_predictions))\n"
      ],
      "metadata": {
        "id": "wdsHAEVz0B4d",
        "outputId": "138c523c-96d9-4697-a5fc-505daacba213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 0s 1ms/step\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Classification Report for Random Forest - Training Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.99      0.93      6374\n",
            "           1       0.90      0.50      0.64      1626\n",
            "\n",
            "    accuracy                           0.89      8000\n",
            "   macro avg       0.89      0.74      0.79      8000\n",
            "weighted avg       0.89      0.89      0.87      8000\n",
            "\n",
            "\n",
            "Classification Report for Random Forest - Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.91      1589\n",
            "           1       0.80      0.38      0.51       411\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.83      0.68      0.71      2000\n",
            "weighted avg       0.85      0.85      0.83      2000\n",
            "\n",
            "\n",
            "Classification Report for XGBoost - Training Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.97      0.93      6374\n",
            "           1       0.83      0.51      0.63      1626\n",
            "\n",
            "    accuracy                           0.88      8000\n",
            "   macro avg       0.86      0.74      0.78      8000\n",
            "weighted avg       0.88      0.88      0.87      8000\n",
            "\n",
            "\n",
            "Classification Report for XGBoost - Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91      1589\n",
            "           1       0.73      0.41      0.52       411\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.79      0.68      0.71      2000\n",
            "weighted avg       0.83      0.85      0.83      2000\n",
            "\n",
            "\n",
            "Classification Report for Neural Network - Training Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.96      6374\n",
            "           1       0.90      0.81      0.85      1626\n",
            "\n",
            "    accuracy                           0.94      8000\n",
            "   macro avg       0.93      0.89      0.91      8000\n",
            "weighted avg       0.94      0.94      0.94      8000\n",
            "\n",
            "\n",
            "Classification Report for Neural Network - Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.89      0.88      1589\n",
            "           1       0.54      0.48      0.51       411\n",
            "\n",
            "    accuracy                           0.81      2000\n",
            "   macro avg       0.71      0.69      0.70      2000\n",
            "weighted avg       0.80      0.81      0.81      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 ב . all 3 models gave similar score and the training set was higher on all 3 than the test set so there might be a little over-fitting but based on the accuracy the random forest slightly has the best accuracy."
      ],
      "metadata": {
        "id": "u5DSVmXaoSVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6ג . all 3 of the models did not perform very well when it comes to predicting correctly the class 1 which is the my predecting question whether or not an employee churns or not. but looking at the f1 score, XGBoost had the best score. the f1 score considers both recall and pricision and gives a balance assessment of the performence and is most relevent since a higher F1 score indicates a better balance between correctly identifying positive cases and minimizing false positives and false negatives."
      ],
      "metadata": {
        "id": "FsSKNKHpp6Ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7\n",
        "\n",
        "# Split the data into training (80%) and the rest (20%)\n",
        "#X_train, X_temp, y_train, y_temp = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the remaining data into validation (50%) and test (50%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X1_test, y1_test, test_size=0.5, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=128, activation='LeakyReLU', input_dim=8))\n",
        "model.add(Dense(units=64, activation='LeakyReLU'))\n",
        "model.add(Dense(units=32, activation='LeakyReLU'))\n",
        "model.add(Dense(units=16, activation='LeakyReLU'))\n",
        "# model.add(Dropout(0.5))  # Dropout layer for regularization\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(lr=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Define batch size and number of epochs\n",
        "batch_size = 64\n",
        "epochs = 100  # Experiment with the number of epochs\n",
        "\n",
        "# Define EarlyStopping callback to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model with validation\n",
        "history = model.fit(\n",
        "    X1_train,\n",
        "    y1_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[early_stopping],\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X1_test, y1_test)\n",
        "\n",
        "\n",
        "\n",
        "# print(model.summary())\n",
        "\n",
        "# Print the test accuracy\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "y1_pred_prob = model.predict(X1_test)\n",
        "y1_pred = (y1_pred_prob >= 0.5).astype(int)\n",
        "\n",
        "precision = precision_score(y1_test, y1_pred)\n",
        "recall = recall_score(y1_test, y1_pred)\n",
        "f1 = f1_score(y1_test, y1_pred)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1:\", f1)\n",
        "train_predictions = model.predict(X1_train)\n",
        "train_classifications = (train_predictions >= 0.5).astype(int)\n",
        "\n",
        "# Classify test set predictions\n",
        "\n",
        "print(\"Predictions on the training set:\")\n",
        "print(train_classifications)\n",
        "\n",
        "# Predictions on the test set\n",
        "test_predictions = model.predict(X1_test)\n",
        "test_classifications = (test_predictions >= 0.5).astype(int)\n",
        "print(\"\\nPredictions on the test set:\")\n",
        "print(test_classifications)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hqy-Pj_RWSU",
        "outputId": "5ff0fe3b-e4d8-4be2-ad63-9a03b1a9a7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.4469 - accuracy: 0.8177 - val_loss: 0.3988 - val_accuracy: 0.8340\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8419 - val_loss: 0.3731 - val_accuracy: 0.8350\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8543 - val_loss: 0.3557 - val_accuracy: 0.8390\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8543 - val_loss: 0.3610 - val_accuracy: 0.8490\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8574 - val_loss: 0.3566 - val_accuracy: 0.8480\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8568 - val_loss: 0.3587 - val_accuracy: 0.8530\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8570 - val_loss: 0.3721 - val_accuracy: 0.8090\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3440 - accuracy: 0.8586 - val_loss: 0.3533 - val_accuracy: 0.8510\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.8625 - val_loss: 0.3576 - val_accuracy: 0.8470\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.8597 - val_loss: 0.3556 - val_accuracy: 0.8440\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8630 - val_loss: 0.3546 - val_accuracy: 0.8520\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.8596 - val_loss: 0.3551 - val_accuracy: 0.8530\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.8605 - val_loss: 0.3648 - val_accuracy: 0.8420\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8619 - val_loss: 0.3593 - val_accuracy: 0.8490\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3375 - accuracy: 0.8635 - val_loss: 0.3596 - val_accuracy: 0.8410\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.3362 - accuracy: 0.8635 - val_loss: 0.3636 - val_accuracy: 0.8380\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3356 - accuracy: 0.8621 - val_loss: 0.3532 - val_accuracy: 0.8380\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3331 - accuracy: 0.8634 - val_loss: 0.3606 - val_accuracy: 0.8500\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3330 - accuracy: 0.8650 - val_loss: 0.3526 - val_accuracy: 0.8430\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8620 - val_loss: 0.3614 - val_accuracy: 0.8460\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8621 - val_loss: 0.3575 - val_accuracy: 0.8470\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3332 - accuracy: 0.8640 - val_loss: 0.3640 - val_accuracy: 0.8440\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3322 - accuracy: 0.8626 - val_loss: 0.3543 - val_accuracy: 0.8480\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.8648 - val_loss: 0.3679 - val_accuracy: 0.8370\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3287 - accuracy: 0.8655 - val_loss: 0.3758 - val_accuracy: 0.8340\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8648 - val_loss: 0.3645 - val_accuracy: 0.8470\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8660 - val_loss: 0.3680 - val_accuracy: 0.8490\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8648 - val_loss: 0.3630 - val_accuracy: 0.8460\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8652 - val_loss: 0.3610 - val_accuracy: 0.8450\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8460\n",
            "Test Accuracy: 0.8460000157356262\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Precision: 0.7136929460580913\n",
            "Recall: 0.41849148418491483\n",
            "F1: 0.5276073619631901\n",
            "250/250 [==============================] - 0s 1ms/step\n",
            "Predictions on the training set:\n",
            "[[1]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [1]]\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "\n",
            "Predictions on the test set:\n",
            "[[1]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "on question 5 i Have already experemented with the network trying to get the best score by adding and removing layers and playing with the parameters but here i tried a diffrent activation methods and found a better one that improves the network score of accuracy pricision recall and f1."
      ],
      "metadata": {
        "id": "g_lyLX2i3Zej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9\n",
        "X2_train, X2_test, y2_train, y2_test = preliminary_processing(X2, y2,2)"
      ],
      "metadata": {
        "id": "kmWkxqmw6MdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10\n",
        "\n",
        "model = LinearRegression()  # Replace with your desired model\n",
        "model.fit(X2_train, y2_train)\n",
        "\n",
        "y2_train_pred = model.predict(X2_train)\n",
        "\n",
        "# Perform predictions on the test set\n",
        "y2_test_pred = model.predict(X2_test)\n",
        "\n",
        "# Assuming you have already trained your model and made predictions\n",
        "# 'y2_train_pred' contains predictions on the training set\n",
        "# 'y2_test_pred' contains predictions on the test set\n",
        "\n",
        "# Calculate R-squared (R^2) for training and test sets\n",
        "r2_train = r2_score(y2_train, y2_train_pred)\n",
        "r2_test = r2_score(y2_test, y2_test_pred)\n",
        "\n",
        "# Calculate Root Mean Square Error (RMSE) for training and test sets\n",
        "rmse_train = np.sqrt(mean_squared_error(y2_train, y2_train_pred))\n",
        "rmse_test = np.sqrt(mean_squared_error(y2_test, y2_test_pred))\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE) for training and test sets\n",
        "mae_train = mean_absolute_error(y2_train, y2_train_pred)\n",
        "mae_test = mean_absolute_error(y2_test, y2_test_pred)\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error (MAPE) for training and test sets\n",
        "mape_train = np.mean(np.abs((y2_train - y2_train_pred) / y2_train)) * 100\n",
        "mape_test = np.mean(np.abs((y2_test - y2_test_pred) / y2_test)) * 100\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"R-squared (R^2) - Training Set:\", r2_train)\n",
        "print(\"R-squared (R^2) - Test Set:\", r2_test)\n",
        "print(\"Root Mean Square Error (RMSE) - Training Set:\", rmse_train)\n",
        "print(\"Root Mean Square Error (RMSE) - Test Set:\", rmse_test)\n",
        "print(\"Mean Absolute Error (MAE) - Training Set:\", mae_train)\n",
        "print(\"Mean Absolute Error (MAE) - Test Set:\", mae_test)\n",
        "print(\"Mean Absolute Percentage Error (MAPE) - Training Set:\", mape_train)\n",
        "print(\"Mean Absolute Percentage Error (MAPE) - Test Set:\", mape_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvFHnAYt9hBN",
        "outputId": "616dd6cc-9af6-4106-9c1d-927aa6faa829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared (R^2) - Training Set: 0.9999995615146176\n",
            "R-squared (R^2) - Test Set: 0.9999995687063579\n",
            "Root Mean Square Error (RMSE) - Training Set: 1909.4481826505387\n",
            "Root Mean Square Error (RMSE) - Test Set: 1872.9733880054828\n",
            "Mean Absolute Error (MAE) - Training Set: 1485.1395150759918\n",
            "Mean Absolute Error (MAE) - Test Set: 1474.947410341857\n",
            "Mean Absolute Percentage Error (MAPE) - Training Set: 0.10353261481587009\n",
            "Mean Absolute Percentage Error (MAPE) - Test Set: 0.09404217176921102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already loaded and split your dataset into X2_train, X2_test, y2_train, and y2_test\n",
        "\n",
        "# Define the range of polynomial degrees (d values)\n",
        "d_values = [2, 3, 4]  # You can extend this list as needed\n",
        "\n",
        "best_result = None\n",
        "best_model = None  # Initialize a variable to store the best model\n",
        "poly_X2_train = None\n",
        "poly_X2_test = None\n",
        "\n",
        "# Iterate over each polynomial degree (d)\n",
        "for d in d_values:\n",
        "    # Create polynomial features\n",
        "    poly = PolynomialFeatures(degree=d)\n",
        "    poly_X_train = poly.fit_transform(X2_train)\n",
        "    poly_X_test = poly.transform(X2_test)\n",
        "\n",
        "    # Initialize Lasso and Ridge models\n",
        "    lasso = Lasso()\n",
        "    ridge = Ridge()\n",
        "\n",
        "    # Define regularization strength values to search\n",
        "    alphas = np.logspace(-6, 6, 13)\n",
        "\n",
        "    # Perform GridSearchCV to find the best alpha value for Lasso\n",
        "    lasso_cv = GridSearchCV(lasso, param_grid={'alpha': alphas}, cv=5)\n",
        "    lasso_cv.fit(poly_X_train, y2_train)\n",
        "    best_lasso_alpha = lasso_cv.best_params_['alpha']\n",
        "\n",
        "    # Perform GridSearchCV to find the best alpha value for Ridge\n",
        "    ridge_cv = GridSearchCV(ridge, param_grid={'alpha': alphas}, cv=5)\n",
        "    ridge_cv.fit(poly_X_train, y2_train)\n",
        "    best_ridge_alpha = ridge_cv.best_params_['alpha']\n",
        "\n",
        "    # Determine the best model based on cross-validation\n",
        "    if lasso_cv.best_score_ > ridge_cv.best_score_:\n",
        "        best_model = lasso_cv.best_estimator_  # Store the best Lasso model\n",
        "        poly_X2_train = poly_X_train\n",
        "        poly_X2_test = poly_X_test\n",
        "        best_alpha = best_lasso_alpha\n",
        "    else:\n",
        "        best_model = ridge_cv.best_estimator_  # Store the best Ridge model\n",
        "        poly_X2_train = poly_X_train\n",
        "        poly_X2_test = poly_X_test\n",
        "        best_alpha = best_ridge_alpha\n",
        "\n",
        "    # Update the best result if it's the first iteration or if this result is better\n",
        "    if best_result is None or lasso_cv.best_score_ > best_result['score']:\n",
        "        best_result = {\n",
        "            'Degree (d)': d,\n",
        "            'Best Model (Lasso/Ridge)': best_model,\n",
        "            'Best Alpha': best_alpha,\n",
        "            'score': lasso_cv.best_score_\n",
        "        }\n",
        "\n",
        "# Print the best transformation degree, best model, and best alpha\n",
        "print(\"Best Transformation Degree (d):\", best_result['Degree (d)'])\n",
        "print(\"Best Model (Lasso/Ridge):\", best_result['Best Model (Lasso/Ridge)'])\n",
        "print(\"Best Alpha:\", best_result['Best Alpha'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmGLmbz-l9UG",
        "outputId": "475e2d02-bbae-44c0-da40-24ac1087c471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Transformation Degree (d): 2\n",
            "Best Model (Lasso/Ridge): Lasso(alpha=10.0)\n",
            "Best Alpha: 10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12\n",
        "The problam that can occur is it can result in a high-dimensional feature space, making the model more sensitive to noise and irrelevant information.\n",
        "to fix this problem we use techniques like Lasso it shrinks less important features and reduces the dimensionality problem."
      ],
      "metadata": {
        "id": "OwpwIs_GyOiw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lasso - uses L1 regularization, which adds penalties to parameters that are not contributing to the prediction, effectively reducing the number of parameters used in prediction.\n",
        "should be used-  when dealing with a large number of parameters and there is concern about too many irrelevant parameters.\n",
        "Ridge - uses L2 regularization, which adds nearly equal penalties to all parameters, shrinking their values uniformly.\n",
        "should be used - when there is noise in the data and the aim is to reduce large parameter values to improve model generalization."
      ],
      "metadata": {
        "id": "ZAeQ8q-eS0e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 13\n",
        "# Assuming you have the best model from section 11 stored in 'best_model'\n",
        "# Make predictions on the training and test sets\n",
        "y_train_pred = best_model.predict(poly_X2_train)\n",
        "y_test_pred = best_model.predict( poly_X2_test)\n",
        "\n",
        "# Import necessary libraries for evaluation metrics\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Calculate R-squared (R^2)\n",
        "r2_train = r2_score(y2_train, y_train_pred)\n",
        "r2_test = r2_score(y2_test, y_test_pred)\n",
        "\n",
        "# Calculate Root Mean Square Error (RMSE)\n",
        "rmse_train = mean_squared_error(y2_train, y_train_pred, squared=False)\n",
        "rmse_test = mean_squared_error(y2_test, y_test_pred, squared=False)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae_train = mean_absolute_error(y2_train, y_train_pred)\n",
        "mae_test = mean_absolute_error(y2_test, y_test_pred)\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error (MAPE)\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "mape_train = mean_absolute_percentage_error(y2_train, y_train_pred)\n",
        "mape_test = mean_absolute_percentage_error(y2_test, y_test_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"R-squared (R^2) - Training Set:\", r2_train)\n",
        "print(\"R-squared (R^2) - Test Set:\", r2_test)\n",
        "print(\"Root Mean Square Error (RMSE) - Training Set:\", rmse_train)\n",
        "print(\"Root Mean Square Error (RMSE) - Test Set:\", rmse_test)\n",
        "print(\"Mean Absolute Error (MAE) - Training Set:\", mae_train)\n",
        "print(\"Mean Absolute Error (MAE) - Test Set:\", mae_test)\n",
        "print(\"Mean Absolute Percentage Error (MAPE) - Training Set:\", mape_train)\n",
        "print(\"Mean Absolute Percentage Error (MAPE) - Test Set:\", mape_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQuHB25lGPbG",
        "outputId": "07b11f74-7a04-40c3-ec42-7fa824d95946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared (R^2) - Training Set: 0.9999995584631569\n",
            "R-squared (R^2) - Test Set: 0.9999995656114722\n",
            "Root Mean Square Error (RMSE) - Training Set: 1916.0806776722243\n",
            "Root Mean Square Error (RMSE) - Test Set: 1879.6814356316122\n",
            "Mean Absolute Error (MAE) - Training Set: 1492.9514162567039\n",
            "Mean Absolute Error (MAE) - Test Set: 1478.6091082970852\n",
            "Mean Absolute Percentage Error (MAPE) - Training Set: 0.10480350878148387\n",
            "Mean Absolute Percentage Error (MAPE) - Test Set: 0.09424987176058297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 14\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBRegressor\n",
        "# from catboost import CatBoostRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Define a dictionary of models and their respective hyperparameter grids\n",
        "models = {\n",
        "    'XGBRegressor': (XGBRegressor(), {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "    }),\n",
        "    # 'CatBoostRegressor': (CatBoostRegressor(), {\n",
        "    #     'iterations': [100, 200, 300],\n",
        "    #     'learning_rate': [0.01, 0.1, 0.2],\n",
        "    # }),\n",
        "    'LGBMRegressor': (LGBMRegressor(), {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "    }),\n",
        "    # 'RandomForestRegressor': (RandomForestRegressor(), {\n",
        "    #     'n_estimators': [100, 200, 300],\n",
        "    #     'max_depth': [None, 10, 20],\n",
        "    # })\n",
        "}\n",
        "\n",
        "best_model = None\n",
        "best_params = {}\n",
        "best_score = -1\n",
        "\n",
        "for model_name, (model, param_grid) in models.items():\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1)\n",
        "    grid_search.fit(X1_train, y1_train)\n",
        "\n",
        "    if grid_search.best_score_ > best_score:\n",
        "        best_score = grid_search.best_score_\n",
        "        best_model = model_name\n",
        "        best_params = grid_search.best_params_\n",
        "\n",
        "# Print the best model and its parameters\n",
        "print(f\"Best Model: {best_model}\")\n",
        "print(f\"Best Parameters: {best_params}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQbAij9Lqed1",
        "outputId": "96ecba0d-86ef-4084-a415-0c9c93049142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 854\n",
            "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 0.203250\n",
            "Best Model: LGBMRegressor\n",
            "Best Parameters: {'learning_rate': 0.01, 'n_estimators': 300}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15\n",
        "# Create the selected model using the best hyperparameters\n",
        "selected_model = models[best_model][0]\n",
        "selected_model.set_params(**best_params)\n",
        "\n",
        "# Fit the selected model on the training data\n",
        "selected_model.fit(X1_train, y1_train)\n",
        "\n",
        "# Make predictions on the training and test sets\n",
        "y1_train_pred = selected_model.predict(X1_train)\n",
        "y1_test_pred = selected_model.predict(X1_test)\n",
        "\n",
        "# Calculate R-squared (R^2)\n",
        "r2_train = r2_score(y1_train, y1_train_pred)\n",
        "r2_test = r2_score(y1_test, y1_test_pred)\n",
        "\n",
        "# Calculate Root Mean Square Error (RMSE)\n",
        "rmse_train = np.sqrt(mean_squared_error(y1_train, y1_train_pred))\n",
        "rmse_test = np.sqrt(mean_squared_error(y1_test, y1_test_pred))\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae_train = mean_absolute_error(y1_train, y1_train_pred)\n",
        "mae_test = mean_absolute_error(y1_test, y1_test_pred)\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error (MAPE)\n",
        "mape_train = np.mean(np.abs((y1_train - y1_train_pred) / y1_train)) * 100\n",
        "mape_test = np.mean(np.abs((y1_test - y1_test_pred) / y1_test)) * 100\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Training R^2: {r2_train}\")\n",
        "print(f\"Test R^2: {r2_test}\")\n",
        "print(f\"Training RMSE: {rmse_train}\")\n",
        "print(f\"Test RMSE: {rmse_test}\")\n",
        "print(f\"Training MAE: {mae_train}\")\n",
        "print(f\"Test MAE: {mae_test}\")\n",
        "print(f\"Training MAPE: {mape_train}%\")\n",
        "print(f\"Test MAPE: {mape_test}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly3fnlBKww5d",
        "outputId": "b67fad1f-e6f2-493a-be89-d9b48b0cd60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 854\n",
            "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 0.203250\n",
            "Training R^2: 0.4307534561979889\n",
            "Test R^2: 0.30576540930712914\n",
            "Training RMSE: 0.30361730039988966\n",
            "Test RMSE: 0.3366712165656241\n",
            "Training MAE: 0.20360965994445165\n",
            "Test MAE: 0.22850266834731758\n",
            "Training MAPE: inf%\n",
            "Test MAPE: inf%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import zipfile\n",
        "\n",
        "# Path to the uploaded zip file\n",
        "uploaded_zip_file = '/content/drive/MyDrive/archive (2).zip'\n",
        "\n",
        "# Define the paths to the folders containing your image data\n",
        "shells_folder = 'Shells'\n",
        "pebbles_folder = 'Pebbles'\n",
        "\n",
        "# Create directories to extract the files if they don't exist\n",
        "os.makedirs(shells_folder, exist_ok=True)\n",
        "os.makedirs(pebbles_folder, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(uploaded_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')\n",
        "\n",
        "# Verify if the folders exist\n",
        "print(\"Shells Folder Exists:\", os.path.exists(shells_folder))\n",
        "print(\"Pebbles Folder Exists:\", os.path.exists(pebbles_folder))\n",
        "\n",
        "# Load and preprocess image data\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Load shells images and assign label 0\n",
        "for filename in os.listdir(shells_folder):\n",
        "    if filename.endswith('.jpg'):\n",
        "        img_path = os.path.join(shells_folder, filename)\n",
        "        image = cv2.imread(img_path)  # Load the image\n",
        "        image = cv2.resize(image, (224, 224))  # Resize to a consistent size\n",
        "        X.append(image)\n",
        "        y.append(0)  # Label for shells\n",
        "\n",
        "# Load pebbles images and assign label 1\n",
        "for filename in os.listdir(pebbles_folder):\n",
        "    if filename.endswith('.jpg'):\n",
        "        img_path = os.path.join(pebbles_folder, filename)\n",
        "        image = cv2.imread(img_path)  # Load the image\n",
        "        image = cv2.resize(image, (224, 224))  # Resize to a consistent size\n",
        "        X.append(image)\n",
        "        y.append(1)  # Label for pebbles\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Shuffle the data\n",
        "indices = np.arange(X.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "X = X[indices]\n",
        "y = y[indices]\n",
        "\n",
        "print(len(X))  # Length of X, the image data\n",
        "print(len(y))\n",
        "\n",
        "# Now, X contains your image data, and y contains the corresponding labels.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e4WyEqy6bbB",
        "outputId": "738cde70-fb3d-4216-dfdc-80f7a3045b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shells Folder Exists: True\n",
            "Pebbles Folder Exists: True\n",
            "4244\n",
            "4244\n"
          ]
        }
      ]
    }
  ]
}